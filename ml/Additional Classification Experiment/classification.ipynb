{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case\n",
    "\n",
    "Classification of Glass type. It contains 10 attributes(unit measurement: weight percent in corresponding oxide): RI: refractive index, Na: Sodium, Mg: Magnesium, Al: Aluminum, Si: Silicon, K: Potassium, Ca: Calcium, Ba: Barium, Fe: Iron .The response is glass type: 1 building windows float processed, 2 building windows nonfloat processed, 3 vehicle windows float processed, 4 vehicle windows nonfloat processed, 5 containers, 6 tableware, 7 headlamps. Table with imported data is shown below. CSV file is available here: [Data](https://www.kaggle.com/uciml/glass)\n",
    "\n",
    "![dataset](./data.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preparation of the resource\n",
    "\n",
    "1. Log into Azure portal and create Azure Machine Learning resource.\n",
    "2. Download necessary data and notebook file.\n",
    "3. Go to Azure Macine Learning Studio. \n",
    "4. Create new Dataset with downloaded csv file as it is shown on first picture.\n",
    "5. Create compute instace: \n",
    "![dataset](./cluster.png)\n",
    "6. Import notebook file, replace campute instance name and file name if it is needed and run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Get Workspace defined in by default config.json file\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously imported data from Azure ML Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "aml_dataset = ws.datasets['glass-data']\n",
    "\n",
    "# Use Pandas DataFrame just to check schema\n",
    "full_df = aml_dataset.to_pandas_dataframe()\n",
    "full_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.518365</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>2.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>2.103739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.511150</td>\n",
       "      <td>10.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>69.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.516523</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517680</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>72.790000</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.519157</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.533930</td>\n",
       "      <td>17.380000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>75.410000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.190000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RI          Na          Mg          Al          Si           K  \\\n",
       "count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       "mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       "std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       "25%      1.516523   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       "50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       "75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       "\n",
       "               Ca          Ba          Fe        Type  \n",
       "count  214.000000  214.000000  214.000000  214.000000  \n",
       "mean     8.956963    0.175047    0.057009    2.780374  \n",
       "std      1.423153    0.497219    0.097439    2.103739  \n",
       "min      5.430000    0.000000    0.000000    1.000000  \n",
       "25%      8.240000    0.000000    0.000000    1.000000  \n",
       "50%      8.600000    0.000000    0.000000    2.000000  \n",
       "75%      9.172500    0.000000    0.100000    3.000000  \n",
       "max     16.190000    3.150000    0.510000    7.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Pandas DataFrame just to investigate the dataset's schema and info\n",
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset in test and train Tabular Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               RI          Na          Mg          Al          Si           K  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  181.000000  181.000000   \n",
      "mean     1.518499   13.405414    2.743370    1.413757   72.631657    0.498453   \n",
      "std      0.003105    0.819509    1.419048    0.493881    0.806918    0.687429   \n",
      "min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
      "25%      1.516550   12.930000    2.200000    1.180000   72.280000    0.140000   \n",
      "50%      1.517780   13.270000    3.480000    1.350000   72.780000    0.550000   \n",
      "75%      1.519260   13.800000    3.610000    1.580000   73.080000    0.600000   \n",
      "max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
      "\n",
      "               Ca          Ba          Fe        Type  \n",
      "count  181.000000  181.000000  181.000000  181.000000  \n",
      "mean     8.972983    0.157403    0.053481    2.640884  \n",
      "std      1.423647    0.493052    0.090606    2.010607  \n",
      "min      5.870000    0.000000    0.000000    1.000000  \n",
      "25%      8.230000    0.000000    0.000000    1.000000  \n",
      "50%      8.590000    0.000000    0.000000    2.000000  \n",
      "75%      9.140000    0.000000    0.100000    3.000000  \n",
      "max     16.190000    3.150000    0.370000    7.000000  \n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = aml_dataset.random_split(0.8, seed=234)\n",
    "\n",
    "train_dataset_df = train_dataset.to_pandas_dataframe()\n",
    "test_dataset_df = test_dataset.to_pandas_dataframe()\n",
    "\n",
    "print(train_dataset_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Compute Instance\n",
    "Provide name of your compute cluster created in step 5 of preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing training cluster.\n",
      "Checking cluster status...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"automl-cluster\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "     found = True\n",
    "     print('Found existing training cluster.')\n",
    "     # Get existing cluster\n",
    "     # Method 1:\n",
    "     aml_remote_compute = cts[amlcompute_cluster_name]\n",
    "     # Method 2:\n",
    "     # aml_remote_compute = ComputeTarget(ws, amlcompute_cluster_name)\n",
    "    \n",
    "if not found:\n",
    "     print('Creating a new training cluster...')\n",
    "     provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D13_V2\", \n",
    "                                                                 max_nodes = 20)\n",
    "     # Create the cluster.\n",
    "     aml_remote_compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "\n",
    "aml_remote_compute.wait_for_completion(show_output = True, min_node_count = 0, timeout_in_minutes = 20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 0,\n",
       " 'targetNodeCount': 0,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 0,\n",
       "  'idleNodeCount': 0,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2020-12-29T15:56:20.165000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2020-12-29T14:25:42.793760+00:00',\n",
       " 'modifiedTime': '2020-12-29T14:25:58.595569+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 0,\n",
       "  'maxNodeCount': 1,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT120S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_DS2_V2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For additional details of current AmlCompute status:\n",
    "aml_remote_compute.get_status().serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List primary metric to drive the AutoML classification problem\n",
    "Chosen primary metric is 'accuracy' where closer to 1.00 is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_macro_recall',\n",
       " 'average_precision_score_weighted',\n",
       " 'precision_score_weighted',\n",
       " 'AUC_weighted',\n",
       " 'accuracy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train import automl\n",
    "\n",
    "# Get a list of valid metrics for your given task\n",
    "automl.utilities.get_primary_metrics('classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AutoML Experiment settings\n",
    "Chosen settings are:\n",
    "- Label column name - Type\n",
    "- Task - classification\n",
    "- Metric - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "project_folder = './automlclassification'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=aml_remote_compute,\n",
    "                             task='classification',\n",
    "                             primary_metric='accuracy',\n",
    "                             experiment_timeout_minutes=15,                            \n",
    "                             training_data=train_dataset,\n",
    "                             label_column_name=\"Type\",\n",
    "                             n_cross_validations=5,                                                \n",
    "                             iteration_timeout_minutes=5,                                                    \n",
    "                             enable_early_stopping=True,\n",
    "                             featurization='auto',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             verbosity=logging.INFO,\n",
    "                             path=project_folder\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classif-automl-remote-12-29-2020-16\n",
      "Running on remote.\n",
      "No run_configuration provided, running on automl-cluster with default configuration\n",
      "Running on remote compute: automl-cluster\n",
      "Parent Run ID: AutoML_df6c5ca5-b72f-4a45-9ce2-c869166ace33\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|7                                |6                                |181                                   |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:53       0.7565    0.7565\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:48       0.7342    0.7565\n",
      "         2   MinMaxScaler RandomForest                      0:00:48       0.7239    0.7565\n",
      "         3   MinMaxScaler RandomForest                      0:00:47       0.6628    0.7565\n",
      "         4   MinMaxScaler RandomForest                      0:00:54       0.7844    0.7844\n",
      "         5   MinMaxScaler SVM                               0:00:48       0.6688    0.7844\n",
      "         6   MaxAbsScaler GradientBoosting                  0:00:54       0.7402    0.7844\n",
      "         7   StandardScalerWrapper RandomForest             0:00:54       0.7512    0.7844\n",
      "         8   SparseNormalizer XGBoostClassifier             0:00:51       0.7511    0.7844\n",
      "         9   SparseNormalizer LightGBM                      0:00:54       0.6683    0.7844\n",
      "        10   RobustScaler RandomForest                      0:00:51       0.6791    0.7844\n",
      "        11   MaxAbsScaler LightGBM                          0:00:54       0.7071    0.7844\n",
      "        12   SparseNormalizer XGBoostClassifier             0:00:52       0.7399    0.7844\n",
      "        13   RobustScaler ExtremeRandomTrees                0:00:48       0.6796    0.7844\n",
      "        14   StandardScalerWrapper XGBoostClassifier        0:00:50       0.7399    0.7844\n",
      "        15    VotingEnsemble                                0:01:00       0.8008    0.8008\n",
      "        16    StackEnsemble                                 0:01:00       0.7676    0.8008\n",
      "Manual run timing: --- 1612.970469236374 seconds needed for running the whole Remote AutoML Experiment ---\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "time_string = now.strftime(\"%m-%d-%Y-%H\")\n",
    "experiment_name = \"classif-automl-remote-{0}\".format(time_string)\n",
    "print(experiment_name)\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "            \n",
    "run = experiment.submit(automl_config, show_output=True)\n",
    "\n",
    "print('Manual run timing: --- %s seconds needed for running the whole Remote AutoML Experiment ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Parent Run Time needed for the whole AutoML process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Timing: --- 1580.0 seconds needed for running the whole Remote AutoML Experiment ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "run_details = run.get_details()\n",
    "\n",
    "end_time_utc_str = run_details['endTimeUtc'].split(\".\")[0]\n",
    "start_time_utc_str = run_details['startTimeUtc'].split(\".\")[0]\n",
    "timestamp_end = time.mktime(datetime.strptime(end_time_utc_str, \"%Y-%m-%dT%H:%M:%S\").timetuple())\n",
    "timestamp_start = time.mktime(datetime.strptime(start_time_utc_str, \"%Y-%m-%dT%H:%M:%S\").timetuple())\n",
    "\n",
    "parent_run_time = timestamp_end - timestamp_start\n",
    "print('Run Timing: --- %s seconds needed for running the whole Remote AutoML Experiment ---' % (parent_run_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the 'Best Model' for later testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: classif-automl-remote-12-29-2020-16,\n",
      "Id: AutoML_df6c5ca5-b72f-4a45-9ce2-c869166ace33_15,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('datatransformer',\n",
      "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "                                 feature_sweeping_config=None,\n",
      "                                 feature_sweeping_timeout=None,\n",
      "                                 featurization_config=None, force_text_dnn=None,\n",
      "                                 is_cross_validation=None,\n",
      "                                 is_onnx_compatible=None, logger=None,\n",
      "                                 observer=None, task=None, working_dir=None)),\n",
      "                ('prefittedsoftvotingclassifier',...\n",
      "                                                                                               max_delta_step=0,\n",
      "                                                                                               max_depth=3,\n",
      "                                                                                               min_child_weight=1,\n",
      "                                                                                               missing=nan,\n",
      "                                                                                               n_estimators=100,\n",
      "                                                                                               n_jobs=1,\n",
      "                                                                                               nthread=None,\n",
      "                                                                                               objective='multi:softprob',\n",
      "                                                                                               random_state=0,\n",
      "                                                                                               reg_alpha=0,\n",
      "                                                                                               reg_lambda=1,\n",
      "                                                                                               scale_pos_weight=1,\n",
      "                                                                                               seed=None,\n",
      "                                                                                               silent=None,\n",
      "                                                                                               subsample=1,\n",
      "                                                                                               tree_method='auto',\n",
      "                                                                                               verbose=-10,\n",
      "                                                                                               verbosity=0))],\n",
      "                                                                     verbose=False))],\n",
      "                                               flatten_transform=None,\n",
      "                                               weights=[0.2, 0.2, 0.2, 0.2,\n",
      "                                                        0.2]))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model: Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature columns from test dataset and convert to NumPi array for predicting \n",
    "Quality of wine is the feature we are about to classify with the best model so it has to be removed from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if 'Type' in test_dataset_df.columns:\n",
    "    y_test_df = test_dataset_df.pop('Type')\n",
    "\n",
    "x_test_df = test_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 predictions: \n",
      "[1 2 1 1 1 2 2 1 1 2 2 2 2 2 2 2 2 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "# Use of the best model\n",
    "y_predictions = fitted_model.predict(x_test_df)\n",
    "\n",
    "print('20 predictions: ')\n",
    "print(y_predictions[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Accuracy with Test Dataset compared to previously removed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy:')\n",
    "accuracy_score(y_test_df, y_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
